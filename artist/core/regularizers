import torch

from artist.util.environment_setup import get_device


def total_variation_loss(
    surfaces: torch.Tensor,
    number_of_neighbors: int = 20,
    sigma: float | None = None,
    batch_size: int = 512,
    epsilon: float = 1e-8,
    device: torch.device | None = None,
) -> torch.Tensor:
    """
    Compute the total variation loss for facetted surfaces.

    This loss term can be used as an addition to the overall loss during the surface reconstruction
    optimization. It supresses the noise in the surface. It measures the noise in the surface by
    taking absolute differences in the z values of the provided points. This loss implementation
    focuses on local smoothness by applying a Gaussian distance weight and thereby letting
    closer points contribute more. This loss implementation is batched and can handle multiple
    surfaces which are further batched in facets.

    Parameters
    ----------
    surfaces : torch.Tensor
        The surfaces.
        Tensor of shape [number_of_active_heliostats, number_of_facets_per_surface, number_of_surface_points_per_facet, 4].
    number_of_neighbors : int
        The number of nearest neighbors to consider (default is 20).
    sigma : float | None
        Determines how quickly the weight falls off as the distance increases (default is None).
    batch_size : int
        Used to process smaller batches of points instead of creating full distance matrices for all points (default is 512).
    epsilon : float
        A small vlaue used to prevent divisions by zero (defualt is 1e-8).
    device : torch.device | None
        The device on which to perform computations or load tensors and models (default is None).
        If None, ARTIST will automatically select the most appropriate
        device (CUDA or CPU) based on availability and OS.

    Returns
    -------
    torch.Tensor
        The total variation loss for all provided surfaces.
        Tensor of shape [number_of_active_heliostats, number_of_facets_per_surface].
    """
    device = get_device(device=device)

    number_of_surfaces, number_of_facets, number_of_surface_points_per_facet, _ = (
        surfaces.shape
    )
    coordinates = surfaces[:, :, :, :2]
    z_values = surfaces[:, :, :, 2]

    if sigma is None:
        coordinates_std = coordinates.std(dim=1).mean().item()
        sigma = max(coordinates_std * 0.1, 1e-6)
    sigma = float(sigma + 1e-12)

    variation_loss_sum = torch.zeros(
        (number_of_surfaces, number_of_facets), device=device
    )
    number_of_valid_neighbors = torch.zeros(
        (number_of_surfaces, number_of_facets), device=device
    )

    # Iterate over query points in batches to limit memory usage.
    for start_index in range(0, number_of_surface_points_per_facet, batch_size):
        end_index = min(start_index + batch_size, number_of_surface_points_per_facet)
        number_of_points_in_batch = end_index - start_index

        batch_coordinates = coordinates[:, :, start_index:end_index, :]
        batch_z_values = z_values[:, :, start_index:end_index]

        # Compute pairwise distances between the current batch coordinates and all coordinates and exclude identities.
        distances = torch.cdist(batch_coordinates, coordinates)
        rows = torch.arange(number_of_points_in_batch, device=device)
        cols = (start_index + rows).to(device)
        self_mask = torch.zeros_like(distances, dtype=torch.bool)
        self_mask[:, :, rows, cols] = True
        masked_distances = torch.where(
            self_mask, torch.full_like(distances, 1e9), distances
        )

        # Select the k nearest neighbors (or fewer if the coordinate is near an edge).
        number_of_neighbors_to_select = min(
            number_of_neighbors, number_of_surface_points_per_facet - 1
        )
        selected_distances, selected_indices = torch.topk(
            masked_distances, number_of_neighbors_to_select, largest=False, dim=3
        )
        valid_mask = selected_distances < 1e9

        # Get all z_values of the selected neighbors and the absolute z_value_variations.
        z_values_neighbors = torch.gather(
            z_values.unsqueeze(2).expand(-1, -1, number_of_points_in_batch, -1),
            3,
            selected_indices,
        )
        z_value_variations = torch.abs(
            batch_z_values.unsqueeze(-1) - z_values_neighbors
        )
        z_value_variations = z_value_variations * valid_mask.type_as(z_value_variations)

        # Accumulate weighted z_value_variations.
        weights = torch.exp(-0.5 * (selected_distances / sigma) ** 2)
        weights = weights * valid_mask.type_as(weights)
        variation_loss_sum = variation_loss_sum + (weights * z_value_variations).sum(
            dim=(2, 3)
        )
        number_of_valid_neighbors = number_of_valid_neighbors + valid_mask.type_as(
            z_value_variations
        ).sum(dim=(2, 3))

    # Batched total variation losses.
    variation_loss_final = variation_loss_sum / (number_of_valid_neighbors + epsilon)

    return variation_loss_final
